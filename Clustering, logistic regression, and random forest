#open data and load library
library(readxl)
BankChurners <- read_excel("University/DSMA Master/Thesis DSMA/Credit card data/BankChurners.csv/BankChurners.xlsx")
library(factoextra)
library(cluster)
library(fpc)
library(SoftClustering)
library(tidyverse)
library(kableExtra)
library(dplyr)
library(ggplot2)
library(readr)
library(Rtsne) #for applying t-SNE (dimension reduction to visualize K-medoid results)
library(ppclust)
library(stats)
library(reshape2)
library(fclust)
library(splitTools)
library(ranger)
library(caret)
library(randomForest)
library(writexl)
library(broom)
library(car)
library(iml)

#data pre-processing
str(BankChurners)
BankChurners <- BankChurners[,-(22:23)] #remove the last 2 columns 
BankChurners$CLIENTNUM <- factor(BankChurners$CLIENTNUM)
BankChurners$female <- ifelse(BankChurners$Gender == "F", 1, 0)
BankChurners$female <- factor(BankChurners$female)
BankChurners$churn <- ifelse(BankChurners$Attrition_Flag == "Existing Customer", 0, 1)
BankChurners$churn <- factor(BankChurners$churn)  
#BankChurners$Attrition_Flag <- factor(BankChurners$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(BankChurners$Gender)
BankChurners$Education_Level <- factor(BankChurners$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=TRUE)
BankChurners$Marital_Status <- factor(BankChurners$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=TRUE)
BankChurners$Income_Category <- factor(BankChurners$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = TRUE)
BankChurners$Card_Category <- factor(BankChurners$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=TRUE)
str(BankChurners)
BankChurners <- BankChurners[,-c(2,4)]
summary(BankChurners)

#look at summary statistics for churn vs. no churn 
BankChurners[,c(2:11,21)] %>% 
  filter(churn == 0) %>%
  summary() %>%
  kbl(caption = "Summary Statistics for Customers Who Did Not Churn") %>%
  kable_classic(full_width = F, html_font = "Cambria")

BankChurners[,c(12:19, 21)] %>% 
  filter(churn == 0) %>%
  summary() %>%
  kbl(caption = "Summary Statistics for Customers Who Did Not Churn") %>%
  kable_classic(full_width = F, html_font = "Cambria")

BankChurners[,c(2:11,21)] %>% 
  filter(churn == 1) %>%
  summary() %>%
  kbl(caption = "Summary Statistics for Customers Who Churned") %>%
  kable_classic(full_width = F, html_font = "Cambria")

BankChurners[,c(12:19, 21)] %>% 
  filter(churn == 1) %>%
  summary() %>%
  kbl(caption = "Summary Statistics for Customers Who Churned") %>%
  kable_classic(full_width = F, html_font = "Cambria")

#trying to create boxplots for stat summary
ggplot(BankChurners, aes(x = churn, y = Customer_Age)) +
  geom_boxplot()

numeric.data <- BankChurners[,c(2,3,8:19,21)]
data.for.boxplots <- melt(numeric.data, id = "churn")
fig <- function(width, heigth){
  options(repr.plot.width = width, repr.plot.height = heigth)
}
fig(10, 4)
ggplot(data.for.boxplots, aes(x=variable, y=value, fill=churn)) + 
  geom_boxplot() +
  facet_wrap(~variable, scale="free")

#descriptive statistics for categorical variables
table(BankChurners$Education_Level, BankChurners$churn)
prop.table(table(BankChurners$Education_Level, BankChurners$churn))

table(BankChurners$Marital_Status, BankChurners$churn)
prop.table(table(BankChurners$Marital_Status, BankChurners$churn))

table(BankChurners$Income_Category, BankChurners$churn)
prop.table(table(BankChurners$Income_Category, BankChurners$churn))

table(BankChurners$Card_Category, BankChurners$churn)
prop.table(table(BankChurners$Card_Category, BankChurners$churn))

#proportion of churning
prop.table(table(BankChurners$churn))

###########################################################
######-------------------KMEANS----------------------------
###########################################################
#kmeans subset data
kmeansdata <- BankChurners[,c(8:10,16,17)] #inactivity, length, relations, frequency, monetary
summary(kmeansdata)
boxplot(kmeansdata$Months_on_book, kmeansdata$Total_Relationship_Count, kmeansdata$Months_Inactive_12_mon, kmeansdata$Total_Trans_Amt, kmeansdata$Total_Trans_Ct)
boxplot(kmeansdata$Total_Trans_Amt, plot = FALSE)
kmeansdata <- scale(kmeansdata, center = TRUE, scale = TRUE)
kmeansdata <- as.data.frame(kmeansdata)

#distance <- get_dist(kmeansdata) #too big to be visualized
#fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))

#elbow method 1 with fviz_nbclust
set.seed(123)
fviz_nbclust(kmeansdata, kmeans, method = "wss") +
  labs(title = "Scree Plot for K-Means")

#elbow method 2 with own function 
set.seed(123)
# function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(kmeansdata, k, iter.max = 100, nstart = 10 )$tot.withinss
}
#compute and plot wss for k = 1 to k = 15
k.values <- 1:15
#extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)
plot(k.values, wss_values,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Total within-clusters sum of squares")

#silhouette method 1 
set.seed(123)
sil.kmeans <- fviz_nbclust(kmeansdata[,-6], kmeans, method = "silhouette") +
  labs(title = "Silhouette for K-means")
sil.kmeans$data #silhouette for kmeans is 0.3141582

#plotting the silhouette for rough kmeans
silho.kmeans2 <- NA
set.seed(123)
for (i in 2:10) {
  kmeans.final2 <- kmeans(kmeansdata, centers = i, iter.max = 100, nstart = 10)
  sil.kmeans2 <- SIL(kmeansdata, kmeans.final2$cluster)
  silho.kmeans2[i] <- sil.kmeans2$sil
}

plot(1:10, silho.roughkmeans,
     xlab = "Number of clusters",
     ylab = "Average Silhouette Width",main="Silhouette for Rough K-Means")
lines(1:10, silho.roughkmeans)

#gap statistic
set.seed(123)
gap_stat <- clusGap(kmeansdata, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
fviz_gap_stat(gap_stat)

#compute k-means clustering with k = 2 and make the plots
set.seed(123)
final <- kmeans(kmeansdata, 2, nstart = 25)
print(final)
fviz_cluster(final, data = kmeansdata)
#clusplot(kmeansdata[,1:5], kmeansdata$cluster, color=TRUE, shade=TRUE,
         labels=2, lines=0, main = "K-Means Results")
plotcluster(kmeansdata[,1:5], final$cluster)

#compute summary statistics of the clusters 
kmeansdata %>%
  mutate(Cluster = final$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")

#input the cluster and churn description in kmeansdata
kmeansdata$cluster <- final$cluster
kmeansdata$churn <- BankChurners$churn

aggregate(cbind(Months_on_book, Total_Relationship_Count, Months_Inactive_12_mon, Total_Trans_Amt, Total_Trans_Ct, churn) ~ cluster, FUN=mean, data=kmeansdata)

kmeansdata %>%
  group_by(cluster) %>%
  summarize(n=n(),
            Months_on_book = mean(Months_on_book),
            Total_Relationship_Count = mean(Total_Relationship_Count), 
            Months_Inactive_12_mon = mean(Months_Inactive_12_mon),
            Total_Trans_Amt = mean(Total_Trans_Amt),
            Total_Trans_Ct = mean(Total_Trans_Ct))

prop.table(table(kmeansdata$cluster, kmeansdata$churn)) 

#convert results to fclust
kmeans.converted <- ppclust2(final, "fclust")
sil.kmeans <- Fclust.index(final, "SIL")
sil.kmeans <- SIL(kmeansdata, final$cluster)


###########################################################
######-----------------ROUGH KMEANS------------------------
###########################################################

#rough kmeans subset data
rough.kmeansdata <- BankChurners[,c(8:10,16,17)] #inactivity, length, relations, frequency, monetary
summary(rough.kmeansdata)
rough.kmeansdata <- scale(rough.kmeansdata, center = TRUE, scale = TRUE)
rough.kmeansdata <- as.data.frame(rough.kmeansdata)

rough.final <- RoughKMeans_LW(rough.kmeansdata, meansMatrix = 2, nClusters = 2, maxIterations = 100)
SoftClustering:::plotRoughKMeans(rough.kmeansdata, upperMShipMatrix = rough.final$upperApprox, meansMatrix = rough.final$clusterMeans, plotDimensions = c(1,2), colouredPlot = TRUE)
sil.roughkmeans <- SIL(rough.kmeansdata, rough.final$upperApprox) #silhouette average for rough kmeans is 0.3563982

#plotting the silhouette for rough kmeans
silho.roughkmeans <- NA
for (i in 2:10) {
  rough.final2 <- RoughKMeans_LW(rough.kmeansdata, meansMatrix = 2, nClusters = i, maxIterations = 100)
  sil.roughkmeans2 <- SIL(rough.kmeansdata, rough.final2$upperApprox)
  silho.roughkmeans[i] <- sil.roughkmeans2$sil
}

plot(1:10, silho.roughkmeans,
     xlab = "Number of clusters",
     ylab = "Average Silhouette Width",main="Silhouette for Rough K-Means")
lines(1:10, silho.roughkmeans)

#doing PCA so we can plot the rough kmeans 
pca <- prcomp(rough.kmeansdata)
plot(pca)
summary(pca)

comp <- data.frame(pca$x[,1:2]) #get the first 2 principal components

silho.roughkmeans2 <- NA
for (i in 2:10) {
  rough.final22 <- RoughKMeans_LW(comp, meansMatrix = 2, nClusters = i, maxIterations = 100)
  sil.roughkmeans22 <- SIL(comp, rough.final22$upperApprox)
  silho.roughkmeans2[i] <- sil.roughkmeans22$sil
}

plot(1:10, silho.roughkmeans2,
     xlab = "Number of clusters",
     ylab = "Average Silhouette Width",main="Silhouette for Rough K-Means")
lines(1:10, silho.roughkmeans2)

rough.final22 <- RoughKMeans_LW(comp, meansMatrix = 2, nClusters = 2, maxIterations = 100)
rough.plot <- SoftClustering:::plotRoughKMeans(comp, upperMShipMatrix = rough.final22$upperApprox, meansMatrix = rough.final22$clusterMeans, plotDimensions = c(1,2), colouredPlot = TRUE)

#getting the rough clusters into 1 column 
rough.clusters <- as.data.frame(rough.final$upperApprox)
rough.clusters[3] <- ifelse(rough.clusters$V1 == 1, 1, 2)
rough.clusters <- rough.clusters[,-c(1:2)]
rough.clusters <- as.data.frame(rough.clusters)
rough.kmeansdata$cluster <- rough.clusters$rough.clusters #run this if you want to add the clusters to the rough.kmeansdata
as.factor(rough.kmeansdata$cluster)

#getting the raw rough clusters into the rough.kmeansdata
colnames(rough.clusters) <- c("C1", "C2") #renaming the variables
rough.kmeansdata[,7:8] <- rough.clusters
rough.kmeansdata <- rough.kmeansdata[,-6]
rough.kmeansdata$churn <- BankChurners$churn

#plotting for rough kmeans (2nd method)
rough.tsne <- Rtsne(rough.kmeansdata, check_duplicates = FALSE)
rough.tsne_data <- rough.tsne$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(rough.clusters$rough.clusters))
ggplot(aes(x = X, y = Y), data = rough.tsne_data) +
  geom_point(aes(color = cluster))+
  ggtitle("Rough K-Means for Credit Card Churn") #works but the plot looks funny

# function taken from SMDM Assignment 3
seg.summ <- function(data, groups) {
  aggregate(data, list(groups), function(x) mean(as.numeric(x)))
}
rough.kmeans.results <- seg.summ(rough.kmeansdata, rough.clusters$rough.clusters)

#trying to make boxplots out of the clustering result
ggplot(rough.kmeansdata, aes(x = cluster, y = Months_on_book)) +
  geom_boxplot()

rough.boxplots <- melt(rough.kmeansdata, id = "cluster")
rough.boxplots$cluster <- as.factor(rough.boxplots$cluster)
fig <- function(width, heigth){
  options(repr.plot.width = width, repr.plot.height = heigth)
}
fig(10, 4)
ggplot(rough.boxplots, aes(x=variable, y=value, fill=cluster)) + 
  geom_boxplot() +
  facet_wrap(~variable, scale="free") +
  ggtitle("Boxplots for Rough K-Means with 2 Clusters")

#aggregating the means for clusters 1 and 2 using the real data (not scaled data)
rough.data <- BankChurners[,c(8:10,16,17)] #inactivity, length, relations, frequency, monetary
rough.data[,6:7] <- rough.kmeansdata[,6:7]
rough.data$churn <- rough.kmeansdata$churn

#descriptive statistics of the clusters
rough.data[,1:6] %>%
  filter(C1 == 1) %>%
  summarise_all(mean) #for cluster 1
mean(rough.data$Months_on_book[rough.data$C1 == 1])
mean(rough.data$Total_Trans_Amt[rough.data$C1 == 1])
mean(rough.data$Total_Trans_Ct[rough.data$C1 == 1])

rough.data[,c(1:5,7)] %>%
  filter(C2 == 1) %>%
  summarise_all(mean) #for cluster 2
mean(rough.data$Months_on_book[rough.data$C2 == 1])
mean(rough.data$Total_Trans_Amt[rough.data$C2 == 1])
mean(rough.data$Total_Trans_Ct[rough.data$C2 == 1])

#computing the proportions of churning in 2 clusters
cluster1 <- rough.kmeansdata %>%
  filter(C1 == 1)
prop.table(table(cluster1$churn))

cluster2 <- rough.kmeansdata %>%
  filter(C2 == 1)
prop.table(table(cluster2$churn))


#######-------trying rough kmeans with 3 clusters instead------------
rough.final3 <- RoughKMeans_LW(comp, meansMatrix = 2, nClusters = 3, maxIterations = 100)
rough.plot <- SoftClustering:::plotRoughKMeans(comp, upperMShipMatrix = rough.final3$upperApprox, meansMatrix = rough.final3$clusterMeans, plotDimensions = c(1,2), colouredPlot = TRUE)

#getting the raw data and inserting the cluster members + churn 
rough.final33 <- RoughKMeans_LW(rough.kmeansdata[,1:5], meansMatrix = 2, nClusters = 3, maxIterations = 100)
rough.data3 <- BankChurners[,c(8:10,16,17)] #inactivity, length, relations, frequency, monetary
rough.data3[,6:8] <- rough.final33$upperApprox
rough.data3$churn <- BankChurners$churn
colnames(rough.data3)[6:8] <- c("C1", "C2", "C3")

#getting the means of each variable 
rough.data3[,1:6] %>%
  filter(C1 == 1) %>%
  summarise_all(mean) #for cluster 1
mean(rough.data3$Months_on_book[rough.data3$C1 == 1])
mean(rough.data3$Total_Trans_Amt[rough.data3$C1 == 1])
mean(rough.data3$Total_Trans_Ct[rough.data3$C1 == 1])

rough.data3[,c(1:5,7)] %>%
  filter(C2 == 1) %>%
  summarise_all(mean) #for cluster 2
mean(rough.data3$Months_on_book[rough.data3$C2 == 1])
mean(rough.data3$Total_Trans_Amt[rough.data3$C2 == 1])
mean(rough.data3$Total_Trans_Ct[rough.data3$C2 == 1])

rough.data3[,c(1:5,8)] %>%
  filter(C3 == 1) %>%
  summarise_all(mean) #for cluster 3
mean(rough.data3$Months_on_book[rough.data3$C3 == 1])
mean(rough.data3$Total_Trans_Amt[rough.data3$C3 == 1])
mean(rough.data3$Total_Trans_Ct[rough.data3$C3 == 1])

#computing the proportions of churning in 3 clusters
cluster1.3 <- rough.data3 %>%
  filter(C1 == 1)
prop.table(table(cluster1.3$churn))

cluster2.3 <- rough.data3 %>%
  filter(C2 == 1)
prop.table(table(cluster2.3$churn))

cluster3.3 <- rough.data3 %>%
  filter(C3 == 1)
prop.table(table(cluster3.3$churn))

#counting the number of obs in lower approximations for the 3 clusters
sum(cluster1.3$C1[cluster1.3$C2 == 0 & cluster1.3$C3 == 0])
sum(cluster2.3$C2[cluster2.3$C1 == 0 & cluster2.3$C3 == 0])
sum(cluster3.3$C3[cluster3.3$C1 == 0 & cluster3.3$C2 == 0])

write_xlsx(rough.data3, "roughdata3.xlsx")

#########################################################
######-------------------KMEDOIDS------------------------
#########################################################
#Checking distribution of categorical variables
prop.table(table(BankChurners$Education_Level))
prop.table(table(BankChurners$Income_Category))
prop.table(table(BankChurners$Marital_Status))
prop.table(table(BankChurners$Card_Category))

#correlation plot
library(corrplot)
corr <- cor(BankChurners[,-c(1,4:7,20:21)])
corrplot(corr, method="circle")

kmedoidsdata <- BankChurners[,-c(1)]
gower_dist <- daisy(kmedoidsdata, metric = "gower") #Obtain gower distances for variables in good playlist

#selecting no of k
sil_width <- c(NA)
set.seed(123)
for(i in 2:15){  
  pam_fit <- pam(gower_dist, diss = TRUE, k = i)  
  sil_width[i] <- pam_fit$silinfo$avg.width  
}
plot(1:15, sil_width,
     xlab = "Number of clusters",
     ylab = "Average Silhouette Width",main="Silhouette for K-Medoids")
lines(1:15, sil_width)

#result summary of k-medoid 
k <- 2
pam_fit <- pam(gower_dist, diss = TRUE, k) #silhouette for kmedoids is 0.2490123
pam_results <- kmedoidsdata %>%
  mutate(cluster = pam_fit$clustering) %>%
  group_by(cluster) %>%
  do(the_summary = summary(.))
pam_results$the_summary

#visualizing result of k-medoid for 2 clusters
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering))
ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))+
  ggtitle("K-Medoids for Credit Card Churn")


#########################################################
######----------SILHOUETTE COMPILATION-------------------
#########################################################
silhouette <- 2:10
silhouette <- as.data.frame(silhouette)
silhouette$kmeans <- sil.kmeans$data$y[2:10]
silhouette$rough_kmeans <- silho.roughkmeans[2:10]
silhouette$kmedoids <- sil_width[2:10]
colnames(silhouette) <- c("No. of clusters", "K-Means", "Rough K-Means", "K-Medoids")

#plotting the silhouette in 1 graph
sil.boxplots <- melt(silhouette, id = "No. of clusters", variable.name = "Method", value.name = "Average Silhouette")
fig <- function(width, heigth){
  options(repr.plot.width = width, repr.plot.height = heigth)
}
fig(10, 4)
ggplot(sil.boxplots, aes(x= `No. of clusters`, y=`Average Silhouette`)) + 
  geom_line(aes(colour = Method)) +
  ggtitle("Average Silhouette Comparison")


#########################################################
######----------DATA PREP FOR CHURNING PREDICTION--------
#########################################################
churn.data <- BankChurners
churn.data[,22:23] <- rough.data[,6:7]
summary(churn.data)
churn.data$Education_Level <- factor(churn.data$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered = FALSE)
churn.data$Marital_Status <- factor(churn.data$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered = FALSE)
churn.data$Income_Category <- factor(churn.data$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
churn.data$Card_Category <- factor(churn.data$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered = FALSE)

cluster1.data <- churn.data %>%
  filter(C1 == 1)

cluster2.data <- churn.data %>%
  filter(C2 == 1)

summary(cluster1.data)
summary(cluster2.data)
prop.table(table(cluster1.data$churn)) #88.69% nonchurn and 11.31% churn
prop.table(table(cluster2.data$churn)) #82.36% nonchurn and 17.64% churn

#Splitting cluster 1 data into 80% training and 20% testing set using stratified sampling
set.seed(123)
partition.1 <- partition(cluster1.data$churn,p=c(train=0.8,test=0.2),type="stratified")
c1churn.train <- cluster1.data[partition.1$train, ]
c1churn.test <- cluster1.data[partition.1$test, ]
prop.table(table(c1churn.train$churn)) #checking the distribution of cluster 1 churn in training data
prop.table(table(c1churn.test$churn)) #checking the distribution of cluster 1 churn in testing data

#Splitting cluster 2 data into 80% training and 20% testing set using stratified sampling
set.seed(123)
partition.2 <- partition(cluster2.data$churn,p=c(train=0.8,test=0.2),type="stratified")
c2churn.train <- cluster2.data[partition.2$train, ]
c2churn.test <- cluster2.data[partition.2$test, ]
prop.table(table(c2churn.train$churn)) #checking the distribution of cluster 2 churn in training data
prop.table(table(c2churn.test$churn)) #checking the distribution of cluster 2 churn in testing data

#removing unnecessary variables
c1churn.train <- c1churn.train[,-c(1,22,23)]
c1churn.test <- c1churn.test[,-c(1,22,23)]
c2churn.train <- c2churn.train[,-c(1,22,23)]
c2churn.test <- c2churn.test[,-c(1,22,23)]

write_xlsx(rough.data, "roughdata.xlsx")
write_xlsx(churn.data, "churndata.xlsx")
write_xlsx(cluster1.data, "cluster1data.xlsx")
write_xlsx(cluster2.data, "cluster2data.xlsx")
write_xlsx(c1churn.train, "c1churntrain.xlsx")
write_xlsx(c1churn.test, "c1churntest.xlsx")
write_xlsx(c2churn.train, "c2churntrain.xlsx")
write_xlsx(c2churn.test, "c2churntest.xlsx")

#########################################################
######----------------LOGISTIC REGRESSION----------------
#########################################################
cluster1data <- read_excel("cluster1data.xlsx")
cluster2data <- read_excel("cluster2data.xlsx")
c1churntest <- read_excel("c1churntest.xlsx")
c1churntrain <- read_excel("c1churntrain.xlsx")
c2churntest <- read_excel("c2churntest.xlsx")
c2churntrain <- read_excel("c2churntrain.xlsx")

###----------------STRUCTURING DATA...(AGAIN, YES)----------
str(cluster1data)
#cluster1data <- cluster1data[,-(22:23)] #remove the last 2 columns 
#cluster1data$CLIENTNUM <- factor(cluster1data$CLIENTNUM)
#cluster1data$female <- ifelse(cluster1data$Gender == "F", 1, 0)
cluster1data$female <- factor(cluster1data$female)
#cluster1data$churn <- ifelse(cluster1data$Attrition_Flag == "Existing Customer", 0, 1)
cluster1data$churn <- factor(cluster1data$churn)  
#BankChurners$Attrition_Flag <- factor(BankChurners$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(BankChurners$Gender)
cluster1data$Education_Level <- factor(cluster1data$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=FALSE)
cluster1data$Marital_Status <- factor(cluster1data$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=FALSE)
cluster1data$Income_Category <- factor(cluster1data$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
cluster1data$Card_Category <- factor(cluster1data$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=FALSE)

str(cluster2data)
#cluster2data <- cluster2data[,-(22:23)] #remove the last 2 columns 
#cluster2data$CLIENTNUM <- factor(cluster2data$CLIENTNUM)
#cluster2data$female <- ifelse(cluster2data$Gender == "F", 1, 0)
cluster2data$female <- factor(cluster2data$female)
#cluster2data$churn <- ifelse(cluster2data$Attrition_Flag == "Existing Customer", 0, 1)
cluster2data$churn <- factor(cluster2data$churn)  
#BankChurners$Attrition_Flag <- factor(BankChurners$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(BankChurners$Gender)
cluster2data$Education_Level <- factor(cluster2data$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=FALSE)
cluster2data$Marital_Status <- factor(cluster2data$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=FALSE)
cluster2data$Income_Category <- factor(cluster2data$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
cluster2data$Card_Category <- factor(cluster2data$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=FALSE)

str(c1churntrain)
#c1churntrain <- c1churntrain[,-(22:23)] #remove the last 2 columns 
#c1churntrain$CLIENTNUM <- factor(c1churntrain$CLIENTNUM)
#c1churntrain$female <- ifelse(c1churntrain$Gender == "F", 1, 0)
c1churntrain$female <- factor(c1churntrain$female)
#c1churntrain$churn <- ifelse(c1churntrain$Attrition_Flag == "Existing Customer", 0, 1)
c1churntrain$churn <- factor(c1churntrain$churn)  
#BankChurners$Attrition_Flag <- factor(BankChurners$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(BankChurners$Gender)
c1churntrain$Education_Level <- factor(c1churntrain$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=FALSE)
c1churntrain$Marital_Status <- factor(c1churntrain$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=FALSE)
c1churntrain$Income_Category <- factor(c1churntrain$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
c1churntrain$Card_Category <- factor(c1churntrain$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=FALSE)

str(c1churntest)
#c1churntest <- c1churntest[,-(22:23)] #remove the last 2 columns 
#c1churntest$CLIENTNUM <- factor(c1churntest$CLIENTNUM)
#c1churntest$female <- ifelse(c1churntest$Gender == "F", 1, 0)
c1churntest$female <- factor(c1churntest$female)
#c1churntest$churn <- ifelse(c1churntest$Attrition_Flag == "Existing Customer", 0, 1)
c1churntest$churn <- factor(c1churntest$churn)  
#BankChurners$Attrition_Flag <- factor(c1churntest$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(c1churntest$Gender)
c1churntest$Education_Level <- factor(c1churntest$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=FALSE)
c1churntest$Marital_Status <- factor(c1churntest$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=FALSE)
c1churntest$Income_Category <- factor(c1churntest$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
c1churntest$Card_Category <- factor(c1churntest$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=FALSE)

str(c2churntrain)
#c2churntrain <- c2churntrain[,-(22:23)] #remove the last 2 columns 
#c2churntrain$CLIENTNUM <- factor(c2churntrain$CLIENTNUM)
#c2churntrain$female <- ifelse(c2churntrain$Gender == "F", 1, 0)
c2churntrain$female <- factor(c2churntrain$female)
#c2churntrain$churn <- ifelse(c2churntrain$Attrition_Flag == "Existing Customer", 0, 1)
c2churntrain$churn <- factor(c2churntrain$churn)  
#BankChurners$Attrition_Flag <- factor(c2churntrain$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(c2churntrain$Gender)
c2churntrain$Education_Level <- factor(c2churntrain$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=FALSE)
c2churntrain$Marital_Status <- factor(c2churntrain$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=FALSE)
c2churntrain$Income_Category <- factor(c2churntrain$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
c2churntrain$Card_Category <- factor(c2churntrain$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=FALSE)

str(c2churntest)
#c2churntest <- c2churntest[,-(22:23)] #remove the last 2 columns 
#c2churntest$CLIENTNUM <- factor(c2churntest$CLIENTNUM)
#c2churntest$female <- ifelse(c2churntest$Gender == "F", 1, 0)
c2churntest$female <- factor(c2churntest$female)
#c2churntest$churn <- ifelse(c2churntest$Attrition_Flag == "Existing Customer", 0, 1)
c2churntest$churn <- factor(c2churntest$churn)  
#BankChurners$Attrition_Flag <- factor(c2churntest$Attrition_Flag, levels=c("Existing Customer", "Attrited Customer"), ordered=TRUE)
#BankChurners$Gender <- factor(c2churntest$Gender)
c2churntest$Education_Level <- factor(c2churntest$Education_Level, levels=c("Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"), ordered=FALSE)
c2churntest$Marital_Status <- factor(c2churntest$Marital_Status, levels=c("Single", "Married", "Divorced"), ordered=FALSE)
c2churntest$Income_Category <- factor(c2churntest$Income_Category, levels=c("Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"), ordered = FALSE)
c2churntest$Card_Category <- factor(c2churntest$Card_Category, levels=c("Blue", "Silver", "Gold", "Platinum"), ordered=FALSE)

c1churn.train <- c1churntrain
c1churn.test <- c1churntest
c2churn.train <- c2churntrain
c2churn.test <- c2churntest

###BASIC MODEL FOR ASSUMPTION CHECKS
logit.model <- glm(churn ~., data = BankChurners[,-1], family = "binomial")
logit.prob <- predict(logit.model, type = "response")
predicted.classes <- ifelse(logit.prob > 0.5, 1, 0)
head(predicted.classes)

###-----------CHECKING ASSUMPTIONS----------------
##1. LINEARITY ASSUMPTION 
# Select only numeric predictors
numeric.data <- BankChurners %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(numeric.data)
# Bind the logit and tidying the data for plot
numeric.data <- numeric.data %>%
  mutate(logit = log(logit.prob/(1-logit.prob))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(numeric.data, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y") +
  labs(title = "Checking for linearity between the numerical predictors and logit-transformed Churn variable as a response", x = "Logit of Churn", y = "Predictor value")

##2. INFLUENTIAL OBSERVATION ASSUMPTION 
plot(logit.model, which = 4, id.n = 3)

# Extract model results
model.data <- augment(logit.model) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = churn), alpha = .5) +
  theme_bw() +
  labs(title = "Checking for influential observations", x = "Observation", y = "Standardized residual")

##3. MULTICOLLINEARITY ASSUMPTION 
car::vif(logit.model)
vif(logit.model) #seems to be high correlation between Avg_Open_To_Buy and Credit_Limit    
logit.model <- glm(churn ~., data = BankChurners[,-c(1)], family = "binomial")
vif <- as.data.frame(rownames(vif(logit.model))) 
vif[,2] <- vif(logit.model)[,1]
colnames(vif) <- c("Variable", "VIF")
logit.model2 <- glm(churn ~., data = BankChurners[,-c(1,14)], family = "binomial")
vif[1:12,3] <- vif(logit.model2)[1:12,1]
vif[14:19,3] <- vif(logit.model2)[13:18,1]
write_xlsx(vif, "vif.xlsx")

###------------DOING THE LOGISTIC REGRESSION--------------
### Fit the model for cluster 1
c1.model <- glm(churn ~ ., data = c1churn.train[,-13], family = "binomial")
# Summarize the model
summary(c1.model)
# Make predictions
c1.prob <- predict(c1.model, newdata = c1churn.test[,-13], type = "response")
predicted.classes <- ifelse(c1.prob > 0.5, 1, 0)
# Model accuracy
mean(predicted.classes == c1churn.test$churn)

#using caret package
confusionMatrix(table(predict(c1.model, newdata = c1churn.test[,-13], type="response") >= 0.5,
                      c1churn.test$churn == 1)) #accuracy of 95.03% and sensitivity of 97.51%, specificity=75.61%

### Fit the model for cluster 2
c2.model <- glm(churn ~ ., data = c2churn.train[,-13], family = "binomial")
# Summarize the model
summary(c2.model)
# Make predictions
c2.prob <- predict(c2.model, newdata = c2churn.test[,-13], type = "response")
predicted.classes <- ifelse(c2.prob > 0.5, 1, 0)
# Model accuracy
mean(predicted.classes == c2churn.test$churn)

#using caret package
confusionMatrix(table(predict(c2.model, newdata = c2churn.test[,-13], type="response") >= 0.5,
                      c2churn.test$churn == 1)) #accuracy of 90.86% and recall/sensitivity of 96.57%, specificity=64.26%

#########################################################
######-----------------RANDOM FOREST---------------------
#########################################################
# for reproduciblity
set.seed(123)
# default RF model for cluster 1 (untuned)
c1.rfmodel <- randomForest(
  formula = churn ~ .,
  data    = c1churn.train
)
print(c1.rfmodel)
plot(c1.rfmodel)
c1.rftest = predict(c1.rfmodel, newdata=c1churn.test)
table(c1.rftest, c1churn.test$churn)
confusionMatrix(c1.rftest, c1churn.test$churn)

# for reproduciblity
set.seed(123)
# default RF model for cluster 2 (untuned)
c2.rfmodel <- randomForest(
  formula = churn ~ .,
  data    = c2churn.train
)
plot(c2.rfmodel)
print(c2.rfmodel)
c2.rftest = predict(c2.rfmodel, newdata=c2churn.test)
table(c2.rftest, c2churn.test$churn)
confusionMatrix(c2.rftest, c2churn.test$churn)

which.min(c1.rfmodel$err.rate[,1]) #ntree with minimal OOB rate is 329

#try with validation data
x_test <- c1churn.test[setdiff(names(c1churn.test), "churn")]
y_test <- c1churn.test$churn

rf_oob_comp <- randomForest(
  formula = churn ~ .,
  data    = c1churn.train,
  xtest   = x_test,
  ytest   = y_test
)

# extract OOB & validation errors
oob <- rf_oob_comp$err.rate[,1]
validation <- rf_oob_comp$test$err.rate[,1]

oob <- sqrt(rf_oob_comp$mse)
validation <- sqrt(rf_oob_comp$test$mse)

# compare error rates
tibble::tibble(
  `Out of Bag Error` = oob,
  `Test error` = validation,
  ntrees = 1:rf_oob_comp$ntree
) %>%
  gather(Metric, RMSE, -ntrees) %>%
  ggplot(aes(ntrees, RMSE, color = Metric)) +
  geom_line() +
  scale_y_continuous() +
  xlab("Number of trees")

#try tuning mtry 
# names of features
features <- setdiff(names(c1churn.train), "Sale_Price")

set.seed(123)

m2 <- tuneRF(
  x          = c1churn.train[features[-20]],
  y          = c1churn.train$churn,
  ntreeTry   = 500,
  mtryStart  = 5,
  stepFactor = 1.5,
  improve    = 0.01,
  trace      = FALSE      # to not show real-time progress 
) #mtry with minimum OOB error is 15

ames_ranger <- ranger(
  formula   = churn ~ ., 
  data      = c1churn.train, 
  num.trees = 500,
  mtry      = sqrt(19)
)

###########-------------GRID SEARCH FOR CLUSTER 1----------------------
# hyperparameter grid search
hyper_grid <- expand.grid(
  mtry       = seq(4, 19, by = 2),
  node_size  = seq(2, 9, by = 1),
  sample_size = c(.55, .632, .70, .80, 1),
  #replace = c(TRUE, FALSE),
  OOB_RMSE   = 0
)

# total number of combinations
nrow(hyper_grid)
## [1] 320

for(i in 1:nrow(hyper_grid)) {
  # train model
  model <- ranger(
    formula         = churn ~ ., 
    data            = c1churn.train, 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sample_size[i],
    #replace         = hyper_grid$replace[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- model$prediction.error
}

hyper_grid %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10) #best parameters: mtry=10, node_size=6, sample_size=0.8, OOB prediction error=0.02247580

###########-------------BEST RANDOM FOREST MODEL FOR CLUSTER 1----------------------
#with mtry=10, node_size=6, sample_size=80/20
len_churn <- nrow(c1churn.train[c1churn.train$churn==1,])
len_nochurn <- nrow(c1churn.train[c1churn.train$churn==0,])
set.seed(123)
c1.rfmodel <-randomForest(churn~.,data=c1churn.train, ntree=500, mtry=10, nodesize=6, sampsize=c('1'=as.integer(len_churn*0.2),'0'=as.integer(len_nochurn*0.8)), importance=TRUE) 
print(c1.rfmodel) #OOB ERROR: 4.81%
plot(c1.rfmodel)

c1.rftest = predict(c1.rfmodel, newdata=c1churn.test)
table(c1.rftest, c1churn.test$churn)
confusionMatrix(c1.rftest, c1churn.test$churn) #ACCURACY: 95.58%, RECALL: 62.20%
importance(c1.rfmodel)
varImpPlot(c1.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=10, node_size=6, sample_size=0.8 or 80/80 
len_churn <- nrow(c1churn.train[c1churn.train$churn==1,])
len_nochurn <- nrow(c1churn.train[c1churn.train$churn==0,])
set.seed(123)
c1.rfmodel <-randomForest(churn~.,data=c1churn.train, ntree=500, mtry=10, nodesize=6, sampsize=c('1'=as.integer(len_churn*0.8),'0'=as.integer(len_nochurn*0.8)), importance=TRUE) 
print(c1.rfmodel) #OOB ERROR: 2.39%
plot(c1.rfmodel)

c1.rftest = predict(c1.rfmodel, newdata=c1churn.test)
table(c1.rftest, c1churn.test$churn)
confusionMatrix(c1.rftest, c1churn.test$churn) #ACCURACY: 97.65%, RECALL: 82.93%
importance(c1.rfmodel)
varImpPlot(c1.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=10, node_size=6, sample_size=0.2 or 20/20 
len_churn <- nrow(c1churn.train[c1churn.train$churn==1,])
len_nochurn <- nrow(c1churn.train[c1churn.train$churn==0,])
set.seed(123)
c1.rfmodel <-randomForest(churn~.,data=c1churn.train, ntree=500, mtry=10, nodesize=6, sampsize=c('1'=as.integer(len_churn*0.2),'0'=as.integer(len_nochurn*0.2)), importance=TRUE) 
print(c1.rfmodel) #OOB ERROR: 3.15%
plot(c1.rfmodel)

c1.rftest = predict(c1.rfmodel, newdata=c1churn.test)
table(c1.rftest, c1churn.test$churn)
confusionMatrix(c1.rftest, c1churn.test$churn) #ACCURACY: 96.55%, RECALL: 74.39%
importance(c1.rfmodel)
varImpPlot(c1.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#THE BEST RECALL: with mtry=10, node_size=6, sample_size=80 CHURN/20 NOCHURN
len_churn <- nrow(c1churn.train[c1churn.train$churn==1,])
len_nochurn <- nrow(c1churn.train[c1churn.train$churn==0,])
set.seed(123)
c1.rfmodel <-randomForest(churn~.,data=c1churn.train, ntree=500, mtry=10, nodesize=6, sampsize=c('1'=as.integer(len_churn*0.8),'0'=as.integer(len_nochurn*0.2)), importance=TRUE) 
print(c1.rfmodel) #OOB ERROR: 3.01%
plot(c1.rfmodel)

c1.rftest = predict(c1.rfmodel, newdata=c1churn.test)
table(c1.rftest, c1churn.test$churn)
confusionMatrix(c1.rftest, c1churn.test$churn) #ACCURACY: 97.38%, RECALL: 93.90%
importance(c1.rfmodel)
varImpPlot(c1.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=14, node_size=5, sample_size=0.632, replace=false, #OOB error 0.02143845
len_churn <- nrow(c1churn.train[c1churn.train$churn==1,])
len_nochurn <- nrow(c1churn.train[c1churn.train$churn==0,])
set.seed(123)
c1.rfmodel <-randomForest(churn~.,data=c1churn.train, ntree=500, mtry=14, nodesize=5, replace=FALSE, sampsize=c('1'=as.integer(len_churn*0.632),'0'=as.integer(len_nochurn*0.632)), importance=TRUE) 
print(c1.rfmodel)
plot(c1.rfmodel)

c1.rftest = predict(c1.rfmodel, newdata=c1churn.test)
table(c1.rftest, c1churn.test$churn)
confusionMatrix(c1.rftest, c1churn.test$churn)
importance(c1.rfmodel)
varImpPlot(c1.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

###########-------------WITH RANGER, BEST RANDOM FOREST MODEL FOR CLUSTER 1 (NOT USED)----------------------
c1.ranger <- ranger(
  formula = churn ~ ., 
  data = c1churn.train, 
  num.trees = 500,
  mtry = 14,
  min.node.size = 5,
  sample.fraction = .632,
  replace = FALSE,
  importance = "impurity",
  seed  = 123
)
c1.ranger

c1.rangertest = predict(c1.ranger, data=c1churn.test)
table(c1.rangertest$predictions, c1churn.test$churn)
confusionMatrix(c1.rangertest$predictions, c1churn.test$churn) #accuracy=97.51%, sensitivity=99.53%, specificity=81.71% 

###try again
c1.ranger <- ranger(
  formula = churn ~ ., 
  data = c1churn.train, 
  num.trees = 500,
  mtry = 10,
  min.node.size = 6,
  sample.fraction = .8,
  replace = TRUE,
  importance = "impurity",
  seed  = 123
)
c1.ranger

c1.rangertest = predict(c1.ranger, data=c1churn.test)
table(c1.rangertest$predictions, c1churn.test$churn)
confusionMatrix(c1.rangertest$predictions, c1churn.test$churn) #accuracy=97.65%, sensitivity=99.53%, specificity=82.93% 

###########-------------GRID SEARCH FOR CLUSTER 2----------------------
# hyperparameter grid search
hyper_grid2 <- expand.grid(
  mtry       = seq(4, 19, by = 2),
  node_size  = seq(2, 9, by = 1),
  sample_size = c(.55, .632, .70, .80, 1),
  replace = c(TRUE, FALSE),
  OOB_RMSE   = 0
)

# total number of combinations
nrow(hyper_grid2)
## [1] 320

for(i in 1:nrow(hyper_grid2)) {
  # train model
  model <- ranger(
    formula         = churn ~ ., 
    data            = c2churn.train, 
    num.trees       = 500,
    mtry            = hyper_grid2$mtry[i],
    min.node.size   = hyper_grid2$node_size[i],
    sample.fraction = hyper_grid2$sample_size[i],
    replace         = hyper_grid2$replace[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid2$OOB_RMSE[i] <- model$prediction.error
}

hyper_grid2 %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10) #best parameters: mtry=8, node_size=4, sample_size=0.7, OOB prediction error=0.04043761

###########-------------BEST RANDOM FOREST MODEL FOR CLUSTER 2----------------------
#THE BEST: with mtry=8, node_size=4, sample_size=70/30
len_churn2 <- nrow(c2churn.train[c2churn.train$churn==1,])
len_nochurn2 <- nrow(c2churn.train[c2churn.train$churn==0,])
set.seed(123)
c2.rfmodel <-randomForest(churn~.,data=c2churn.train, ntree=500, mtry=8, nodesize=4, sampsize=c('1'=as.integer(len_churn*0.7),'0'=as.integer(len_nochurn*0.3)), importance=TRUE) 
print(c2.rfmodel) #OOB ERROR: 4.82%
plot(c2.rfmodel)

c2.rftest = predict(c2.rfmodel, newdata=c2churn.test)
table(c2.rftest, c2churn.test$churn)
confusionMatrix(c2.rftest, c2churn.test$churn) #ACCURACY: 95.35%, RECALL: 84.95%
importance(c2.rfmodel)
varImpPlot(c2.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=8, node_size=5, sample_size=70/30, replace=FALSE
len_churn2 <- nrow(c2churn.train[c2churn.train$churn==1,])
len_nochurn2 <- nrow(c2churn.train[c2churn.train$churn==0,])
set.seed(123)
c2.rfmodel <-randomForest(churn~.,data=c2churn.train, ntree=500, mtry=8, nodesize=5, sampsize=c('1'=as.integer(len_churn*0.7),'0'=as.integer(len_nochurn*0.3)), replace = FALSE, importance=TRUE) 
print(c2.rfmodel) #OOB ERROR: 4.75%
plot(c2.rfmodel)

c2.rftest = predict(c2.rfmodel, newdata=c2churn.test)
table(c2.rftest, c2churn.test$churn)
confusionMatrix(c2.rftest, c2churn.test$churn) #ACCURACY: 95.79%, RECALL: 86.52%
importance(c2.rfmodel)
varImpPlot(c2.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=8, node_size=4, sample_size=30/70
len_churn2 <- nrow(c2churn.train[c2churn.train$churn==1,])
len_nochurn2 <- nrow(c2churn.train[c2churn.train$churn==0,])
set.seed(123)
c2.rfmodel <-randomForest(churn~.,data=c2churn.train, ntree=500, mtry=8, nodesize=4, sampsize=c('1'=as.integer(len_churn*0.3),'0'=as.integer(len_nochurn*0.7)), importance=TRUE) 
print(c2.rfmodel) #OOB ERROR: 8.25%
plot(c2.rfmodel)

c2.rftest = predict(c2.rfmodel, newdata=c2churn.test)
table(c2.rftest, c2churn.test$churn)
confusionMatrix(c2.rftest, c2churn.test$churn) #ACCURACY: 91.81%, RECALL: 55.17%
importance(c2.rfmodel)
varImpPlot(c2.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=8, node_size=4, sample_size=70/70
len_churn2 <- nrow(c2churn.train[c2churn.train$churn==1,])
len_nochurn2 <- nrow(c2churn.train[c2churn.train$churn==0,])
set.seed(123)
c2.rfmodel <-randomForest(churn~.,data=c2churn.train, ntree=500, mtry=8, nodesize=4, sampsize=c('1'=as.integer(len_churn*0.7),'0'=as.integer(len_nochurn*0.7)), importance=TRUE) 
print(c2.rfmodel) #OOB ERROR: 5.32%
plot(c2.rfmodel)

c2.rftest = predict(c2.rfmodel, newdata=c2churn.test)
table(c2.rftest, c2churn.test$churn)
confusionMatrix(c2.rftest, c2churn.test$churn) #ACCURACY: 95.02%, RECALL: 76.49%
importance(c2.rfmodel)
varImpPlot(c2.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

#with mtry=8, node_size=4, sample_size=30/30
len_churn2 <- nrow(c2churn.train[c2churn.train$churn==1,])
len_nochurn2 <- nrow(c2churn.train[c2churn.train$churn==0,])
set.seed(123)
c2.rfmodel <-randomForest(churn~.,data=c2churn.train, ntree=500, mtry=8, nodesize=4, sampsize=c('1'=as.integer(len_churn*0.3),'0'=as.integer(len_nochurn*0.3)), importance=TRUE) 
print(c2.rfmodel) #OOB ERROR: 6.72%
plot(c2.rfmodel)

c2.rftest = predict(c2.rfmodel, newdata=c2churn.test)
table(c2.rftest, c2churn.test$churn)
confusionMatrix(c2.rftest, c2churn.test$churn) #ACCURACY: 93.74%, RECALL: 69.28%
importance(c2.rfmodel)
varImpPlot(c2.rfmodel) #importance plots: Mean Decrease Accuracy and Gini

###########-------------ALE PLOTS FOR RANDOM FOREST for cluster 1----------------------
len_churn <- nrow(c1churn.train[c1churn.train$churn==1,])
len_nochurn <- nrow(c1churn.train[c1churn.train$churn==0,])
set.seed(123)
c1.rfmodel <-randomForest(churn~.,data=c1churn.train, ntree=500, mtry=10, nodesize=6, sampsize=c('1'=as.integer(len_churn*0.8),'0'=as.integer(len_nochurn*0.2)), importance=TRUE) 
print(c1.rfmodel) #OOB ERROR: 3.01%

X <- c1churn.train[which(names(c1churn.train) != "churn")]

predictor <- Predictor$new(c1.rfmodel, 
                           data = X, 
                           y = c1churn.train$churn,
                           class = "1")

ale <- FeatureEffect$new(predictor, feature = "Dependent_count", method="ale")
ale$plot()

ale$set.feature("Months_on_book")
ale$plot()

ale$set.feature("Total_Relationship_Count")
ale$plot()

ale$set.feature("Contacts_Count_12_mon")
ale$plot()

ale$set.feature("Total_Revolving_Bal")
ale$plot()

ale$set.feature("Total_Trans_Amt")
ale$plot()

ale$set.feature("Total_Trans_Ct")
ale$plot()

ale$set.feature("Total_Amt_Chng_Q4_Q1")
ale$plot()

ale$set.feature("Total_Ct_Chng_Q4_Q1")
ale$plot()

###########-------------ALE PLOTS FOR RANDOM FOREST for cluster 2----------------------
#THE BEST: with mtry=8, node_size=4, sample_size=70/30
len_churn2 <- nrow(c2churn.train[c2churn.train$churn==1,])
len_nochurn2 <- nrow(c2churn.train[c2churn.train$churn==0,])
set.seed(123)
c2.rfmodel <-randomForest(churn~.,data=c2churn.train, ntree=500, mtry=8, nodesize=4, sampsize=c('1'=as.integer(len_churn*0.7),'0'=as.integer(len_nochurn*0.3)), importance=TRUE) 
print(c2.rfmodel) #OOB ERROR: 4.82%

X2 <- c2churn.train[which(names(c2churn.train) != "churn")]

predictor2 <- Predictor$new(c2.rfmodel, 
                           data = X2, 
                           y = c2churn.train$churn,
                           class = "1")

ale2 <- FeatureEffect$new(predictor2, feature = "Dependent_count", method="ale")
ale2$plot()

ale2$set.feature("Total_Relationship_Count")
ale2$plot()

ale2$set.feature("Months_Inactive_12_mon")
ale2$plot()

ale2$set.feature("Contacts_Count_12_mon")
ale2$plot()

ale2$set.feature("Credit_Limit")
ale2$plot()

ale2$set.feature("Total_Revolving_Bal")
ale2$plot()

ale2$set.feature("Total_Amt_Chng_Q4_Q1")
ale2$plot()

ale2$set.feature("Total_Trans_Amt")
ale2$plot()

ale2$set.feature("Total_Trans_Ct")
ale2$plot()

ale2$set.feature("Total_Ct_Chng_Q4_Q1")
ale2$plot()

ale2$set.feature("Customer_Age")
ale2$plot()
